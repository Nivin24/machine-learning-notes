{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees: Theory and Practice\n",
    "This notebook mirrors the markdown modules: intro, entropy_information_gain, gini_impurity, overfitting_pruning, math_behind, and adds a practical implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Decision Trees are non-parametric models for classification and regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_breast_cancer, make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entropy and Information Gain (Overview)\n",
    "Entropy H = -Σ p log2 p. Information Gain = H(parent) - weighted child entropies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gini Impurity (Overview)\n",
    "Gini = 1 - Σ p^2. CART maximizes decrease in Gini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit a Decision Tree (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "clf = tree.DecisionTreeClassifier(random_state=42, criterion='gini', min_samples_leaf=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize the Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "tree.plot_tree(clf, filled=True, feature_names=[f'f{i}' for i in range(X.shape[1])], class_names=['0','1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning and Pruning (ccp_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [None, 4, 6, 8, 12],\n",
    "    'min_samples_leaf': [1, 5, 10, 20],\n",
    "    'ccp_alpha': [0.0, 0.0005, 0.001, 0.005, 0.01]\n",
    "}\n",
    "gs = GridSearchCV(tree.DecisionTreeClassifier(random_state=42), param_grid, cv=5, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params:', gs.best_params_)\n",
    "print(classification_report(y_test, gs.best_estimator_.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Math Behind Splits (Demonstration)\n",
    "We compute Gini decrease for a toy 1D dataset across thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = make_classification(n_samples=60, n_features=1, n_redundant=0, n_informative=1, n_clusters_per_class=1, random_state=0)\n",
    "x = X1[:,0]\n",
    "order = np.argsort(x)\n",
    "x, y1 = x[order], y1[order]\n",
    "def gini(counts):\n",
    "    n = counts.sum()\n",
    "    if n==0: return 0.0\n",
    "    p = counts / n\n",
    "    return 1.0 - np.sum(p*p)\n",
    "best = (-1, -1)\n",
    "left = np.zeros(2)\n",
    "right = np.bincount(y1, minlength=2).astype(float)\n",
    "G_parent = gini(right)\n",
    "for i in range(len(x)-1):\n",
    "    cls = y1[i]\n",
    "    left[cls]+=1\n",
    "    right[cls]-=1\n",
    "    if x[i]==x[i+1]:\n",
    "        continue\n",
    "    wL = (i+1)/len(x)\n",
    "    wR = 1-wL\n",
    "    score = G_parent - (wL*gini(left) + wR*gini(right))\n",
    "    if score>best[0]:\n",
    "        best = (score, 0.5*(x[i]+x[i+1]))\n",
    "best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.x"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
