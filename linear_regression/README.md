# Linear Regression

Linear regression is one of the fundamental algorithms in machine learning, used for predicting continuous numerical values.

## Overview

Linear regression attempts to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data.

## Types Covered

### Simple Linear Regression
- One independent variable
- Equation: y = mx + b
- Finding the best fit line

### Multiple Linear Regression
- Multiple independent variables
- Equation: y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ
- Matrix representation

## Key Concepts

- **Cost Function**: Mean Squared Error (MSE)
- **Optimization**: Gradient Descent, Normal Equation
- **Assumptions**: Linearity, independence, homoscedasticity
- **Evaluation Metrics**: R², MAE, MSE, RMSE

## Implementation Topics

1. From scratch implementation
2. Using scikit-learn
3. Regularization (Ridge, Lasso)
4. Feature scaling and preprocessing
5. Cross-validation

## Files in this Directory

- `theory.md` - Mathematical foundations
- `implementation.py` - Code examples
- `examples/` - Practice datasets
- `exercises.md` - Hands-on problems

## Prerequisites

Ensure you've completed the prerequisites section, particularly:
- Linear algebra (vectors, matrices)
- Basic calculus (derivatives)
- Python and NumPy basics
